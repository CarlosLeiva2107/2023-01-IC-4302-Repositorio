[//]: # (Portada)
# Instituto Tecnológico de Costa Rica

# Escuela de Computación

# Bases de Datos II GR 1

# Resumen 7

# Google Big Query

# Estudiante: 
# Carlos Eduardo Leiva Medaglia / 2021032973

# Profesor: 
# Gerardo Nereo Campos Araya

# I Semestre 2023
[//]: # (Dejo esto para que el siguiente texto inicie en una nueva página)
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# Como Maneja Google Big Data  

El manejo de Bid Data para google es algo que tiene presente siempre, por esto utilizan un sistema llamado Dremel para escanear a velocidades rápidas y responder consultas en minutos. Dremel utiliza consultas similares a SQL. Google Big Query es la implementación publica de Drremel y proporciona las mismas características que Dremel a desarrolladores externos a traves de un API REST. Dremel cuenta con tan alto rendimiento que permite realizar búsquedas de texto complejas en 35 mil millones de filas en cuestión de segundos.  

# Arquitectura de Dremel  

- Almacenamiento Columnar: Dremel almacena los datos en su formato columnar. Utilizan este formato ya que tiene ventajas como lo son: minimizacion del trafico y mayor relación de comprensión. Tiene la desventaja que no funciona muy bien para actualizar registros, por esto, Dremel no admite operaciones de actualización con este formato.  
- Árbol: Google implemento la estructura de forma de un árbol distribuido masivamente en paralelo para enviar una consulta al árbol y luego agregar los resultados a las hojas a una velocidad increíblemente rápida.  

Gracias a estas arquitecturas que Google implementa es que proporciona un alto rendimiento en sus consultas.  

# BigQuery vs MapReduce  

MapReduce es una tecnología que te permite implementar funciones personalizadas para ejecutar procesos por lotes en cientos o miles de servidores simultáneamente. Map Reduce se ha vuelto muy popular para procesar Big Data en las aplicaciones. Sin embargo, tiene algunas limitaciones, MapReduce está diseñado como un marco de procesamiento por lotes, por lo que no es adecuado para análisis de datos ad hoc y de prueba y error. El tiempo de respuesta es demasiado lento y no permite a los programadores realizar tareas de análisis iterativo o de una sola vez en Big Data, y en caso de que la tarea a realizar sea muy grande, puede tardar inclusive días en completarse, y hasta puede dar resultados incorrectos debido a errores de código del MapReduce.  

Tanto como MapReduce y BigQuery son buenas opciones, sin embargo, dependiendo de lo que se necesite realizar puede ser beneficiosos una opción u otra. BigQuery es adecuado para el uso de procesamiento analítico en línea o inteligencia de negocios, mientras que MapReduce es una mejor opción cuando deseas procesar datos no estructurados. Algunos ejemplos que muestran mejor cuando se debe usar cada uno.  
Usar BigQuery:  
-  Encontrar registros específicos con condiciones especificadas.  
-  Agregación rápida de estadísticas con condiciones que cambian dinámicamente.  
-  Análisis de datos de prueba y error.  

Usar MapReduce:  
-  Ejecutar una minería de datos compleja en Big Data que requiere múltiples iteraciones y rutas de procesamiento de datos.  
-  Ejecutar operaciones de unión grandes.  
-  Exportar grandes cantidades de datos.  


# Soluciones de Data Warehouse y dispositivos para OLAP/BI  

En OLAP/BI existen tres alternativas para solucionar el rendimiento: OLAP relacional, OLAP multidimensional y Exploración Completa.  
El OLAP relacional es una solución basada en base de datos relacionales, se debe construir la mayor cantidad de indices para lograr que tenga alto rendimiento.  
OLAP multidimensional es una solución la cual construye almacenes de datos basados en dimensiones predefinidas, se be invertir mucho tiempo y dinero para poder construir esta solución.  
Ninguna de las dos mencionados anteriormente puede funcionar para realizar consultas complejas, por esto se necesita la exploración completa, y es por esto que se necesita que esta sea lo mas rápida posible. Es por esto que se necesita que el rendimiento de entrada/salida sea lo suficientemente alto para que sea eficiente. BigQuery resuelve el problema de entrada/salida de disco en paralelo al utilizar la economía de escala de la plataforma en la nube. Necesitarías ejecutar simultáneamente 10,000 unidades de disco y 5,000 procesadores para realizar la exploración completa de 1TB de datos en un segundo. Como Google ya posee una gran cantidad de unidades de disco en sus propios centros de datos, los utiliza para lograr este paralelismo masivo.  

# Habilidades de Big Query  
BigQuery ofrece una relación costo-efectividad extremadamente alta y un rendimiento de exploración completa para consultas, gracias a la combinación única de un motor de consulta masivamente paralelo. Big Query es de las soluciones mas baratas que ofrecen en el mercado hoy en dia. Si no utilizamos Big Query realizar una consulta en 35 mil millones de datos sin un indice podría salir extremadamente cara, mientras que utilizando Big Query las empresas se ahorrarías miles de dólares.  
Utilizando Big Query se permite importar su Big Data, llegando a poder importar hasta 100GB en media hora. Pero para esto se necesita utilizar Google Cloud, que es un servicio en la nube que nos permitirá importar nuestros datos.  
Se podría decir que cuando se trata de manejo de Big Data, utilizar Big Query es la mejor solución en el mercado actualmente, y no se tiene mas claro ejemplo que el propio motor de búsqueda Google, que utiliza el mismo sistema, y a la hora de realizar consultas este retorna miles de resultados en cuestión de segundos.